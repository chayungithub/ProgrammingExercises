#################################################
#                  Exercise 2                   #
#################################################
#                    Task 1                     #
#################################################

import pandas as pd
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
import numpy as np
import sklearn
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
import joblib

# import data
df_original = pd.read_csv (r'TV-data.csv')

# Declare required variables
df = df_original[['House', 'TV']]
c_1 = 0
c_2 = 0
c_3 = 0

# Separate each house's data
for i in range(len(df)):
  if df.at[i,'House'] == 1.0:
    c_1 += 1
  elif df.at[i,'House'] == 2.0:
    c_2 += 1
  elif df.at[i,'House'] == 3.0:
    c_3 += 1
df_1 = df.iloc[:c_1,:]
df_2 = df.iloc[c_1 : c_1 + c_2, :]
df_3 = df.iloc[c_1 + c_2:,:]

# Data clustering (k = 3, including, on, off, and stanby mode)
km_1 = KMeans(n_clusters=3).fit(df_1)
centroids_1 = km_1.cluster_centers_
label_1 =km_1.labels_.tolist() 
km_2 = KMeans(n_clusters=2).fit(df_2)
centroids_2 = km_2.cluster_centers_
label_2 =km_2.labels_.tolist() 
km_3 = KMeans(n_clusters=3).fit(df_3)
centroids_3 = km_3.cluster_centers_
label_3 =km_3.labels_.tolist() 

# Plot data in graph
# House 1
fig, axes = plt.subplots(nrows=1, ncols=1)
plt.scatter(df_1['House'], df_1[['TV']], c= km_1.labels_.astype(float), s=50, alpha=0.5)
plt.scatter(centroids_1[:, 0], centroids_1[:, 1], c='red', s=50)
plt.title("House 1")
# House 2
fig, axes = plt.subplots(nrows=1, ncols=1)
plt.scatter(df_2['House'], df_2[['TV']], c= km_2.labels_.astype(float), s=50, alpha=0.5)
plt.scatter(centroids_2[:, 0], centroids_2[:, 1], c='red', s=50)
plt.title("House 2")
# House 3
fig, axes = plt.subplots(nrows=1, ncols=1)
plt.scatter(df_3['House'], df_3[['TV']], c= km_3.labels_.astype(float), s=50, alpha=0.5)
plt.scatter(centroids_3[:, 0], centroids_3[:, 1], c='red', s=50)
plt.title("House 3")

# Label the data
df_1["label"] = label_1
print(df_1)
df_2["label"] = label_2
print(df_2)
df_3["label"] = label_3
print(df_3)

# Add labled data to real data
sum_label = label_1 + label_2 + label_3
df_original["label"] = sum_label
print(df_original)

#################################################
#                    Task 2                     #
#################################################

# Select only Agg column and label column
X = df_original.iloc[:c_1, 3:4]
y = df_original.iloc[:c_1, 4:]
# Separate train and test data to parameters
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)
# Build RandomForestClassifier Machine Learning into a parameter
clf_1 = RandomForestClassifier(max_depth=10, random_state=0)
# Train machine learning by train value
clf_1.fit(X_train, y_train)
# export machine learning
joblib.dump(clf_1, "./random_forest1.joblib")
# Test machine learning by test value with return result class into parameter
y_pred = clf_1.predict(X_test)
# Acurracy compared by y_test and y_predicted
print('accuracy score         :', accuracy_score(y_test, y_pred))
# Print Confusion matrix
print(confusion_matrix(y_test, y_pred))
print(len(X_train), len(X_test))


# Select only Agg column and label column
X = df_original.iloc[c_1 : c_1 + c_2, 3:4]
y = df_original.iloc[c_1 : c_1 + c_2, 4:]
# Separate train and test data to parameters
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)
# Build RandomForestClassifier Machine Learning into a parameter
clf_2 = RandomForestClassifier(max_depth=10, random_state=0)
# Train machine learning by train value
clf_2.fit(X_train, y_train)
# export machine learning
joblib.dump(clf_2, "./random_forest2.joblib")
# Test machine learning by test value with return result class into parameter
y_pred = clf_2.predict(X_test)
# Acurracy compared by y_test and y_predicted
print('accuracy score         :', accuracy_score(y_test, y_pred))
# Print Confusion matrix
print(confusion_matrix(y_test, y_pred))
print(len(X_train), len(X_test))


# Select only Agg column and label column
X = df_original.iloc[c_1 + c_2:, 3:4]
y = df_original.iloc[c_1 + c_2:, 4:]
# Separate train and test data to parameters
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)
# Build RandomForestClassifier Machine Learning into a parameter
clf_3 = RandomForestClassifier(max_depth=10, random_state=0)
# Train machine learning by train value
clf_3.fit(X_train, y_train)
# export machine learning
joblib.dump(clf_3, "./random_forest3.joblib")
# Test machine learning by test value with return result class into parameter
y_pred = clf_3.predict(X_test)
# Acurracy compared by y_test and y_predicted
print('accuracy score         :', accuracy_score(y_test, y_pred))
# Print Confusion matrix
print(confusion_matrix(y_test, y_pred))
print(len(X_train), len(X_test))
